{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "## Fully-connected Layer (퍼셉트론)\n",
    "\n",
    "- FC Layer는 1차원 데이터를 요구\n",
    "- 이미지를 단순하게 1차원으로 바꾸면 2차원 상에서 가지는 정보를 포기해야함\n",
    "  - 이미지 내 사물 간의 거리 관계 등\n",
    "  - 색의 변화 -세로로 변하는 상황\n",
    "- 즉 공간정보(Spatial Information)가 무너짐\n",
    "\n",
    "## Convolutional Neural Network\n",
    "\n",
    "- 따라서 이미지 처리에 특화된 딥러닝 모델이 등장\n",
    "\n",
    "- CNN의 대표적인 구성 요소\n",
    "  - Convolutional Layer\n",
    "  - Pooling Layer\n",
    "  - 분류기(Classifier): Fully-connected layer로 구성\n",
    "\n",
    "- Convolution 연산\n",
    "  - CNN을 구현하는 핵심 연산\n",
    "  - 커널과 Convolution 연산\n",
    "    - 전통적인 이미지 처리 분야에서 커널(필터)이란 것이 존재\n",
    "    - 이미지의 커널 간의 Convolution 연산으로 처리\n",
    "  - 2차원 이미지 데이터: 행렬로 표현 가능\n",
    "    - 행렬의 각 원소는 해당 위치의 이미지 픽셀값\n",
    "  - Convolution 커널 : 행렬로 표현 가능\n",
    "  - Convolution 연산은 2차원 상에서 연산이 이루어지므로 이미지 데이터를 변형 없이 그대로 사용 가능\n",
    "\n",
    "## Convolution 연산 과정\n",
    "\n",
    "- 이미지 * 커널 = 결과\n",
    "\n",
    "### Convolution 연산 용어\n",
    "\n",
    "- 연산 결과 : Feature Map 또는 Activation Map이라 부름\n",
    "- 커널과 이미지가 겹치는 영역 : 수용 영역(Receptive Field)\n",
    "\n",
    "- 컬러 이미지의 Convolution 연산\n",
    "  - 앞선 예시는 이미지의 채널이 1개 = 흑백 이미지\n",
    "  - 컬러 이미지는 채널이 3개\n",
    "  - 이 경우 커널도 채널을 3개로 준비\n",
    "  - 각 채널별로 Convolution 연산을 수행하고 각 결과를 더해서 하나의 Feature Map을 생성\n",
    "  - 커널을 여러 개 두면 Feature Map도 여러개 생성\n",
    "\n",
    "## Convolutional Neural Network\n",
    "\n",
    "- 지금까지 사용한 커널들은 학습 가능한 커널\n",
    "  - 즉 커널 행렬의 각 값들이 가중치\n",
    "- 이러한 커널들로 이루어진 Layer를 Convolutional Layer라고 부름\n",
    "  - 이 Layer들을 쌓아서 CNN을 구성\n",
    "\n",
    "### Layer 역활\n",
    "\n",
    "- 이미지가 가지는 특징 Feature를 뽑아내도록 커널을 학습\n",
    "- 커널에 따라 추출하는 Feature를 다르게 학습\n",
    "- 이미지 내의 대각선, 원형, 색조 등등이 이러한 Feature에 해당\n",
    "\n",
    "### Stride\n",
    "\n",
    "- Convolution 연산 과정을 조절하기 위한 Hyperparameter\n",
    "- 커널 이미지 내에서 이동하는 칸수를 조절\n",
    "\n",
    "### Padding\n",
    "\n",
    "- Padding을 추가하여 Feature Map사이즈가 줄어드는 현상 방지\n",
    "- 또한 이미지의 테두리 정보도 균일하게 활용\n",
    "\n",
    "### Convolutional Layer 의의\n",
    "\n",
    "- 왜 이미지 특징을 잘 뽑아내는가?\n",
    "  - Convolution 연산은 하나의 커널이 픽셀간의 정보를 보게 만듦\n",
    "  - 하나의 커널이 이미지 전체 영역을 보고 학습\n",
    "\n",
    "- Parameter Sharing\n",
    "  - 커널이 가진 Parameter를 이미지의 모든 영역에서 공유\n",
    "  - Parameter 개수를 FC Layer에 비해 극적으로 줄임\n",
    "    - 과적합 방지\n",
    "\n",
    "### Convolutional Layer 활성화 함수\n",
    "\n",
    "- Convolution 연산 또한 선형 연산\n",
    "  - 모두 곱셈과 덧셈으로만 이루어짐\n",
    "\n",
    "- 따라서 FC Layer처럼 비선형성을 추가하기 위해 활성화 함수를 사용\n",
    "  - CNN은 주로 ReLU함수 사용\n",
    "\n",
    "## Pooling Layer\n",
    "\n",
    "- CNN에서 거의 항상 같이 쓰이는 Layer\n",
    "  - 주 역활 : Feature Map의 사이즈를 줄여서 Parameter 개수를 줄이는 것\n",
    "\n",
    "- Max Pooling\n",
    "  - 주어진 이미지나 Feature Map을 더 작은 영역으로 분할\n",
    "  - 위 그림은 각 영역의 크기가 2*2 가 되도록 분할\n",
    "  - 각 영역에서 최대값을 뽑아내어 새로운 Feature Map을 구성\n",
    "\n",
    "- 일반적으로 Max Pooling을 많이 사용\n",
    "  - Feature Map에 존재하는 Feature중 가장 영향력이 큰 Feaure만 사용\n",
    "- Feature Map의 채널이 여러 개면 채널별로 Pooling 연산 수행\n",
    "- 추가 Pooling Layer\n",
    "  - Global Average Pooling 전체 Feature Map에서 하나의 평균값을 계산\n",
    "  - Global Max Pooling 전체 Feature Map에서 하나의 최대값을 계산\n",
    "  - 둘 다 마찬가지로 채널 별로 연산\n",
    "\n",
    "## 분류기 Classifier\n",
    "\n",
    "- CNN은 일반적으로 이미지 분류 목적으로 사용\n",
    "- Feature Map을 Fully-connected Layer에 통과시켜 분류를 수행\n",
    "- 이를 위해 Feature Map을 1차원으로 변형\n",
    "\n",
    "## 대표적인 CNN 모델\n",
    "\n",
    "### LeNet (1990)\n",
    "\n",
    "- 우편번호 인식\n",
    "\n",
    "### AlexNet (2012)\n",
    "\n",
    "- ImageNet Challenge 우승\n",
    "  - ReLU 활성화 함수 소개\n",
    "  - 딥러닝 모델 학습에 GPU를 활용 -> 이후로 사실상 모든 딥러닝 모델은 GPU로 학습\n",
    "\n",
    "### VGGNet (2014)\n",
    "\n",
    "- 커널 사이즈를 모두 3*3으로 통일\n",
    "- Parameter수 증가를 억제하면서 모델 층을 더 많이 쌓을 수 있게 됨\n",
    "- 층이 많을수록 일반적으로 성능이 향상됨\n",
    "\n",
    "### ResNet (2015)\n",
    "\n",
    "- Layer 개수를 최대 152개까지 늘림\n",
    "- 깊은 모델에서 필연적으로 나타나는 현상\n",
    "  - Vanishing Gradient\n",
    "\n",
    "- 기울기 소실 Vanishing Gradient\n",
    "  - 역전파 과정에서 기울기 값이 점점 작아지다 0에 수렴하면서 발생\n",
    "\n",
    "- Residual Connection\n",
    "  - 기울기 소실문제를 해결하기 위한 구조\n",
    "  - 이를 통해 Layer 개수를 극적으로 늘림\n",
    "  - 기존 Convolutional Layer들을 우회하는 연결\n",
    "\n",
    "- 분류 작업이 아닌 경우에 사용하는 모델은\n",
    "  - 일반적으로 분류 모델과 유사하게 CNN을 구성\n",
    "  - 모델의 출력값, 손실 함수, 데이터셋 구성 등이 완전히 다르게 이루어짐\n",
    "    - YOLO, R-CNN, U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow로 conv2d 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]]]], shape=(1, 3, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = tf.ones((1, 3, 3, 1)) # 3x3 x1 이미지가 1개 (1,높이,너비,1)\n",
    "print(inp)\n",
    "\n",
    "# [[[[1][1][1]]\n",
    "#   [[1][1][1]]\n",
    "#   [[1][1][1]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1.]]\n",
      "\n",
      "  [[1.]]]\n",
      "\n",
      "\n",
      " [[[1.]]\n",
      "\n",
      "  [[1.]]]], shape=(2, 2, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "filter = tf.ones((2, 2, 1, 1)) # 2x2 x1 짜리 필터가 1개 \n",
    "print(filter)\n",
    "\n",
    "# [ [ [[1.]],[[1.]] ],\n",
    "#   [ [[1.]],[[1.]] ] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = [1, 1] # [높이, 너비]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[4.]\n",
      "   [4.]]\n",
      "\n",
      "  [[4.]\n",
      "   [4.]]]], shape=(1, 2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output = tf.nn.conv2d(inp, filter, strides ,padding = 'VALID') # padding을 'VALID'으로 설정 = 패딩을 하지 않음\n",
    "print(output)\n",
    "# [[  [[4.] [4.]]\n",
    "#     [[4.] [4.]]  ]], shape=(1, 2, 2, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[16.]]]], shape=(1, 1, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output = tf.nn.conv2d(output, filter, strides, padding = 'VALID') # 한번 더 적용\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow.Keras로 Conv2D 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a72db88ba1b83b14b878414906427eaf31b62ee068e6a91eed760b39b4619b71"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
