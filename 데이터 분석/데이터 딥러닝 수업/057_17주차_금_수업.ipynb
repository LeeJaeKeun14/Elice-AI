{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 기초\n",
    "\n",
    "## 1. 딥러닝 모델의 학습 방법\n",
    "\n",
    "### 딥러닝 모델이란\n",
    "\n",
    "- 히든층이 3층 이상일 시 깊은 신경망이라는 의미의 Deep Learning단어 사용\n",
    "\n",
    "- Node/Unit : 각 층을 구성하는 요소\n",
    "- Layer : 모델을 구성하는 층\n",
    "- Weight : 노드간의 연결 강도(가중치)\n",
    "\n",
    "- 딥러닝 모델의 학습 방법\n",
    "  - Loss function을 최소화하기 위해 최적화 알고리즘을 적용\n",
    "\n",
    "### 손실 함수(Loss Funcion)과 최적화(Optimization)\n",
    "\n",
    "- Loss Function : 예측값과 실제값간의 오차값\n",
    "- Optimization : 오차값을 최소화하는 모델의 인자를 찾는 것\n",
    "\n",
    "- 딥러닝 모델의 학습 방법 이해하기\n",
    "  - 예측값과 실제값 간의 오차값을 최소화하기 위해 오차값을 최소화하는 모델의 인자를 찾는 알고리즘을 적용\n",
    "\n",
    "- 가장 기본적인 최적화 알고리즘, Gradient Descent(GD)\n",
    "  - 신경망의 가중치들을 W라고 했을 때\n",
    "  - 손실함수 Loss(W)의 값을 최소화하기 위해 기울기 Loss(W)를 이용하는 방법\n",
    "\n",
    "- 각 가중치들의 기울기를 구하는 방법\n",
    "  - 딥러닝에서는 역전파(Backpropagation)을 통해 각 가중치들의 기울기를 구할 수 있음\n",
    "\n",
    "### 역전파(Backpropogation)의 정의\n",
    "\n",
    "- 나의 목표 target값과 실제 모델이 예측한 output값이 얼마나 차이나는지 구한 후 오차값을 다시 뒤로 전파해가며 변수들을 갱신하는 알고리즘\n",
    "  - Forward propagation : 순전파\n",
    "  - Backpropagation : 역전파 \n",
    "    - 순전파의 반대 방향으로 이루어지는 과정\n",
    "\n",
    "## 텐서플로우(TensorFlow)\n",
    "\n",
    "### 딥러닝 모델 구현을 위해 학습해야할 분야\n",
    "\n",
    "- python, 하드웨어, C/C++\n",
    "  - 딥러닝 모델, 좋은 연산 장치, 연산 장치 제어\n",
    "\n",
    "- 프레임워크를 통한 딥러닝 모델 구현\n",
    "  - 딥러닝 모델의 학습과 추론을 위한 프로그램\n",
    "  - 딥러닝 모델을 쉽게 구현, 사용가능\n",
    "\n",
    "- 프레임워크 선택하기\n",
    "  - 가장 많이 사용되고, 빠른 성장율을 가진 프레임워크\n",
    "  - TensorFlow 활용\n",
    "\n",
    "### 텐서플로우\n",
    "\n",
    "- 유연하고, 효율적이며, 확장성 있는 딥러닝 프레임워크\n",
    "- 대형 클러스터 컴퓨터부터 스마트폰까지 다양한 디바이스에서 동작\n",
    "\n",
    "- 텐서(Tensor)\n",
    "  - Tensor = Multidimensional Arrays = Data\n",
    "  - 딥러닝에서 텐서는 다차원 배열로 나타내는 데이터를 의미\n",
    "\n",
    "- 플로우(Flow)\n",
    "  - 플로우는 데이터의 흐름을 의미\n",
    "  - 텐서플로우에서 계산은 데이터 플로우 그래프로 수행\n",
    "  - 그래프를 따라 데이터가 노드를 거쳐 흘러가면서 계산\n",
    "\n",
    "- 텐서 + 플로우\n",
    "  - 딥러닝에서 데이터를 의미하는 텐서와\n",
    "  - 데이터 플로우 그래프를 따라 연산이 수행되는 형태의 의미\n",
    "\n",
    "- 텐서플로우 version 1\n",
    "  - 이 전 텐서플로우 1.X 에서는 계산을 위해 그래프 및 세션생성 필요\n",
    "\n",
    "- 직관적인 인터페이스의 텐서플로우 version2\n",
    "  - 즉시실행(Eager Excution)기능을 통해 계산 그래프, 세션 생성 없이 실행 가능\n",
    "\n",
    "## 텐서플로우 기초 사용법\n",
    "\n",
    "### 텐서 다뤄보기\n",
    "\n",
    "- 상수 텐서\n",
    "- 시퀸스 텐서\n",
    "- 변수 텐서\n",
    "\n",
    "### 상수 텐서:Constant Tensor\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "tensor_a = tf.constant(value, dtype=None, shape=None, name=None)\n",
    "```\n",
    "- 반환되는 상수값, 반환되는 tensor타입, tensor의 차원, 텐서 이름 \n",
    "\n",
    "- 다양한 상수 텐서 생성\n",
    "\n",
    "```python\n",
    "tensor_b = tf.zeros(shape, dtype=tf.float32, name=None)\n",
    "\n",
    "tensor_c = tf.ones(shape, dtype=tf.float32, name=None)\n",
    "```\n",
    "\n",
    "### 시퀀스 텐서(Sequence Tensor)\n",
    "\n",
    "```python\n",
    "tensor_d = tf.linspace(start, stop, num, name=None)\n",
    "```\n",
    "- 시작 값, 끝 값, 생성할 데이터 개수, 텐서의 이름\n",
    "\n",
    "```python\n",
    "tensor_e = tf.range(start, limit, delta, name=None)\n",
    "```\n",
    "- 시작 값, 끝 값, 증가량, 텐서의 이름\n",
    "\n",
    "### 변수 텐서(Variable Tensor)\n",
    "\n",
    "\n",
    "```python\n",
    "tensor_f = tf.Variable(initial_value=None, dtype=None, name=None)\n",
    "```\n",
    "- 초기 값, 반환되는 tensor타입, 텐서의 이름\n",
    "\n",
    "- 상수 텐서 샌성 및 수식 정의\n",
    "\n",
    "```python\n",
    "a = tf.constant([1, 0], dtype=tf.float32)\n",
    "\n",
    "def forward(x):\n",
    "  return W * x + b\n",
    "```\n",
    "\n",
    "- 정의된 수식을 활용한 연산\n",
    "\n",
    "```python\n",
    "output = forward(a)\n",
    "print(output)\n",
    "```\n",
    "```\n",
    "tf.Tensor(\n",
    "  [[1. 0.]\n",
    "   [1. 0.]], shape=(2, 2), dtype=float32\n",
    ")\n",
    "```\n",
    "\n",
    "## 텐서플로우로 딥러닝 모델 구현하기\n",
    "\n",
    "### 1. 데이터셋 준비하기\n",
    "\n",
    "- Epoch : 한 번의 epoch는 전체 데이터 셋에 대해 한 번 학습을 완료한 상태\n",
    "- Batch : 나눠진 데이터 셋(보통 mini-batch라고 표현)\n",
    "- iteration : epoch를 나누너서 실행하는 횟수를 의미\n",
    "\n",
    "- Epoch와 Batch 예시\n",
    "  - 총 데이터가 1000개, Batch size = 100\n",
    "    - 1 iteration = 100개 데이터에 대해서 확습\n",
    "    - 1 epoch = 100/Batch size = 10 itreration\n",
    "\n",
    "```python\n",
    "data = np.random.sample((100, 2))\n",
    "labels = np.random.sample((100, 1))\n",
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "```\n",
    "\n",
    "### 2. 딥러닝 모델 구축하기 : 고수준 API 활용\n",
    "\n",
    "- 텐서플로우의 패키지로 제공되는 고수준 API\n",
    "- 딥러닝 모델을 간단하고 빠르게 구현 가능\n",
    "\n",
    "- Karas 메소드\n",
    "  - 모델 클래스 객체 생성\n",
    "\n",
    "```python\n",
    "tf.keras.models.Sequential()\n",
    "```\n",
    "\n",
    "  - 모델의 각 Layer구성\n",
    "```python\n",
    "tf.keras.layers.Dense(units, activation)\n",
    "```\n",
    "  - units: 레이어 안의 Node수\n",
    "  - activation : 적용할 활성함수\n",
    "\n",
    "- Input Layer 의 입력 형태 지정하기\n",
    "  - 첫 번째 즉, Input Layer는 입력 형태에 대한 정보를 필요로 한다.\n",
    "  - input_shape/input_dim 인자 설정하기\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_idm=2, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(10, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "```\n",
    "\n",
    "- Karas 메소드2\n",
    "  - 모델에 Layer 추가하기\n",
    "\n",
    "```python\n",
    "[model].add(tf.keras.layers.Dense(units, activation))\n",
    "```\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, input_idm=2, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "### 3. 딥러닝 모델 학습시키기\n",
    "\n",
    "- 모델 학습 방식을 설정하기 위한 함수\n",
    "\n",
    "```python\n",
    "[model].compile(optimizer, loss)\n",
    "```\n",
    "  - optimiz : 모델 학습 최적화 방법\n",
    "  - loss : 손실 함수 설정\n",
    "\n",
    "- 모델을 학습시키기 위한 함수\n",
    "\n",
    "```python\n",
    "[model].fit(x, y)\n",
    "```\n",
    "  - x : 학습 데이터\n",
    "  - y : 학습 데이터의 label\n",
    "\n",
    "```python\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"SGD\")\n",
    "model.fit(dataset, epochs = 100)\n",
    "```\n",
    "\n",
    "### 4. 평가 및 예측하기\n",
    "\n",
    "- 모델을 평가하기 위한 메소드\n",
    "\n",
    "```python\n",
    "[model].evaluate(x, y)\n",
    "```\n",
    "\n",
    "- 모델로 예측을 수행하기 위한 함수\n",
    "```python\n",
    "[model].predict(x)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
